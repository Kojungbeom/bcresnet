{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597e0ad-ed2c-4d0a-be1b-2436282f60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023 Qualcomm Technologies, Inc.\n",
    "# All Rights Reserved.\n",
    "\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "import shutil\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "### GSC\n",
    "label_dict = {\n",
    "    \"_silence_\": 0,\n",
    "    \"_unknown_\": 1,\n",
    "    \"down\": 2,\n",
    "    \"go\": 3,\n",
    "    \"left\": 4,\n",
    "    \"no\": 5,\n",
    "    \"off\": 6,\n",
    "    \"on\": 7,\n",
    "    \"right\": 8,\n",
    "    \"stop\": 9,\n",
    "    \"up\": 10,\n",
    "    \"yes\": 11,\n",
    "}\n",
    "print(\"labels:\\t\", label_dict)\n",
    "sample_per_cls_v1 = [1854, 258, 257]\n",
    "sample_per_cls_v2 = [3077, 371, 408]\n",
    "SR = 16000\n",
    "\n",
    "\n",
    "def ScanAudioFiles(root_dir, ver):\n",
    "    sample_per_cls = sample_per_cls_v1 if ver == 1 else sample_per_cls_v2\n",
    "    audio_paths, labels = [], []\n",
    "    for path, _, files in sorted(os.walk(root_dir, followlinks=True)):\n",
    "        random.shuffle(files)\n",
    "        for idx, filename in enumerate(files):\n",
    "            if not filename.endswith(\".wav\"):\n",
    "                continue\n",
    "            dataset, class_name = path.split(\"/\")[-2:]\n",
    "            if class_name in (\"_unknown_\", \"_silence_\"):  # balancing\n",
    "                if \"train\" in dataset and idx == sample_per_cls[0]:\n",
    "                    break\n",
    "                if \"valid\" in dataset and idx == sample_per_cls[1]:\n",
    "                    break\n",
    "                if \"test\" in dataset and idx == sample_per_cls[2]:\n",
    "                    break\n",
    "            audio_paths.append(os.path.join(path, filename))\n",
    "            labels.append(label_dict[class_name])\n",
    "    return audio_paths, labels\n",
    "\n",
    "\n",
    "class SpeechCommand(Dataset):\n",
    "    \"\"\"GSC\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, ver, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data_list, self.labels = ScanAudioFiles(root_dir, ver)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.data_list[idx]\n",
    "        sample, _ = torchaudio.load(audio_path)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "\n",
    "\n",
    "def spec_augment(\n",
    "    x, frequency_masking_para=20, time_masking_para=20, frequency_mask_num=2, time_mask_num=2\n",
    "):\n",
    "    lenF, lenT = x.shape[1:3]\n",
    "    # Frequency masking\n",
    "    for _ in range(frequency_mask_num):\n",
    "        f = np.random.uniform(low=0.0, high=frequency_masking_para)\n",
    "        f = int(f)\n",
    "        f0 = random.randint(0, lenF - f)\n",
    "        x[:, f0 : f0 + f, :] = 0\n",
    "    # Time masking\n",
    "    for _ in range(time_mask_num):\n",
    "        t = np.random.uniform(low=0.0, high=time_masking_para)\n",
    "        t = int(t)\n",
    "        t0 = random.randint(0, lenT - t)\n",
    "        x[:, :, t0 : t0 + t] = 0\n",
    "    return x\n",
    "\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(\n",
    "        self,\n",
    "        noise_loc,\n",
    "        device,\n",
    "        hop_length=160,\n",
    "        win_length=480,\n",
    "        n_fft=512,\n",
    "        n_mels=40,\n",
    "        specaug=False,\n",
    "        sample_rate=SR,\n",
    "        frequency_masking_para=7,\n",
    "        time_masking_para=20,\n",
    "        frequency_mask_num=2,\n",
    "        time_mask_num=2,\n",
    "    ):\n",
    "        if noise_loc is None:\n",
    "            self.background_noise = []\n",
    "        else:\n",
    "            self.background_noise = [\n",
    "                torchaudio.load(file_name)[0] for file_name in glob(noise_loc + \"/*.wav\")\n",
    "            ]\n",
    "            assert len(self.background_noise) != 0\n",
    "        self.feature = LogMel(\n",
    "            device,\n",
    "            sample_rate=sample_rate,\n",
    "            hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            n_fft=n_fft,\n",
    "            n_mels=n_mels,\n",
    "        )\n",
    "        self.duration = 2\n",
    "        self.sample_len = sample_rate * self.duration\n",
    "        self.specaug = specaug\n",
    "        self.device = device\n",
    "        if self.specaug:\n",
    "            self.frequency_masking_para = frequency_masking_para\n",
    "            self.time_masking_para = time_masking_para\n",
    "            self.frequency_mask_num = frequency_mask_num\n",
    "            self.time_mask_num = time_mask_num\n",
    "            print(\n",
    "                \"frequency specaug %d %d\" % (self.frequency_mask_num, self.frequency_masking_para)\n",
    "            )\n",
    "            print(\"time specaug %d %d\" % (self.time_mask_num, self.time_masking_para))\n",
    "\n",
    "    def __call__(self, x, labels, augment=True, noise_prob=0.8, is_train=True):\n",
    "        assert len(x.shape) == 3\n",
    "        if augment:\n",
    "            for idx in range(x.shape[0]):\n",
    "                if labels[idx] != 0 and (not is_train or random.random() > noise_prob):\n",
    "                    continue\n",
    "                noise_amp = (\n",
    "                    np.random.uniform(0, 0.1) if labels[idx] != 0 else np.random.uniform(0, 1)\n",
    "                )\n",
    "                noise = random.choice(self.background_noise).to(self.device)\n",
    "                sample_loc = random.randint(0, noise.shape[-1] - (self.sample_len * self.duration))\n",
    "                noise = noise_amp * noise[:, sample_loc : sample_loc + (16000 * self.duration)]\n",
    "                if is_train:\n",
    "                    x_shift = int(np.random.uniform(-0.10, 0.10) * (16000 * self.duration))\n",
    "                    zero_padding = torch.zeros(1, np.abs(x_shift)).to(self.device)\n",
    "                    x = x.to(self.device)\n",
    "                    #print(x.shape, x_shift)\n",
    "                    if x_shift < 0:\n",
    "                        temp_x = torch.cat([zero_padding, x[idx, :, :x_shift]], dim=-1)\n",
    "                    else:\n",
    "                        temp_x = torch.cat([x[idx, :, x_shift:], zero_padding], dim=-1)\n",
    "                    x[idx] = temp_x + noise\n",
    "                else:  # valid\n",
    "                    x[idx] = x[idx] + noise\n",
    "                x[idx] = torch.clamp(x[idx], -1.0, 1.0)\n",
    "\n",
    "        x = self.feature(x)\n",
    "        if self.specaug:\n",
    "            for i in range(x.shape[0]):\n",
    "                x[i] = spec_augment(\n",
    "                    x[i],\n",
    "                    self.frequency_masking_para,\n",
    "                    self.time_masking_para,\n",
    "                    self.frequency_mask_num,\n",
    "                    self.time_mask_num,\n",
    "                )\n",
    "        return x\n",
    "\n",
    "\n",
    "class LogMel:\n",
    "    def __init__(\n",
    "        self, device, sample_rate=SR, hop_length=160, win_length=480, n_fft=512, n_mels=40\n",
    "    ):\n",
    "        self.mel = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            hop_length=hop_length,\n",
    "            n_fft=n_fft,\n",
    "            win_length=win_length,\n",
    "            n_mels=n_mels,\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.mel = self.mel.to(self.device)\n",
    "        output = (self.mel(x) + 1e-6).log()\n",
    "        return output\n",
    "\n",
    "    def spec_augment(self, x, frequency_masking_para, time_masking_para, frequency_mask_num, time_mask_num):\n",
    "        lenF, lenT = x.shape[1:3]\n",
    "        for _ in range(frequency_mask_num):\n",
    "            f = int(np.random.uniform(low=0.0, high=frequency_masking_para))\n",
    "            f0 = random.randint(0, lenF - f)\n",
    "            x[:, f0 : f0 + f, :] = 0\n",
    "        for _ in range(time_mask_num):\n",
    "            t = int(np.random.uniform(low=0.0, high=time_masking_para))\n",
    "            t0 = random.randint(0, lenT - t)\n",
    "            x[:, :, t0 : t0 + t] = 0\n",
    "        return x\n",
    "\n",
    "\n",
    "class Padding:\n",
    "    \"\"\"zero pad to have 1 sec len\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.output_len = SR + SR + SR\n",
    "\n",
    "    def __call__(self, x):\n",
    "        pad_len = self.output_len - x.shape[-1]\n",
    "        if pad_len > 0:\n",
    "            x = torch.cat([x, torch.zeros([x.shape[0], pad_len])], dim=-1)\n",
    "        elif pad_len < 0:\n",
    "            raise ValueError(\"no sample exceed 1sec in GSC.\")\n",
    "        return x\n",
    "\n",
    "def DownloadDataset(loc, url):\n",
    "    if not os.path.isdir(loc):\n",
    "        os.mkdir(loc)\n",
    "    filename = os.path.basename(url)\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "    block_size = 1048576\n",
    "    with open(os.path.join(loc, filename), \"wb\") as f:\n",
    "        for data in response.iter_content(block_size):\n",
    "            f.write(data)\n",
    "            read_so_far = f.tell()\n",
    "            if total_size > 0:\n",
    "                percent = read_so_far * 100 / total_size\n",
    "                print(f\"Downloaded {read_so_far} of {total_size} bytes ({percent:.2f}%)\")\n",
    "    with tarfile.open(os.path.join(loc, filename), \"r:gz\") as tar:\n",
    "        tar.extractall(loc)\n",
    "\n",
    "def make_empty_audio(loc, num):\n",
    "    if not os.path.isdir(loc):\n",
    "        os.mkdir(loc)\n",
    "    for i in range(num):\n",
    "        path = os.path.join(loc, \"%s.wav\" % str(i))\n",
    "        zeros = torch.zeros([1, SR])  # 1 sec long.\n",
    "        torchaudio.save(path, zeros, SR)\n",
    "\n",
    "\n",
    "def make_12class_dataset(base, target):\n",
    "    os.mkdir(target)\n",
    "    os.mkdir(target + \"/_unknown_\")\n",
    "    class10 = [\"down\", \"go\", \"left\", \"no\", \"off\", \"on\", \"right\", \"stop\", \"up\", \"yes\"]\n",
    "    for clsdir in glob(os.path.join(base, \"*\")):\n",
    "        class_name = os.path.basename(clsdir)\n",
    "        if class_name in class10:\n",
    "            target_dir = os.path.join(target, class_name)\n",
    "            shutil.copytree(clsdir, target_dir)\n",
    "            print(f\"Copied {clsdir} to {target_dir}\")\n",
    "        else:\n",
    "            for file_path in glob(os.path.join(clsdir, \"*\")):\n",
    "                filename = os.path.basename(file_path)\n",
    "                target_dir = os.path.join(target, \"_unknown_\")\n",
    "                os.makedirs(target_dir, exist_ok=True)\n",
    "                target_file = os.path.join(target_dir, class_name + \"_\" + filename)\n",
    "                shutil.copy(file_path, target_file)\n",
    "                print(f\"Copied {file_path} to {target_file}\")\n",
    "\n",
    "def split_data(base, target, valid_list, test_list):\n",
    "    with open(valid_list, \"r\") as f:\n",
    "        valid_names = [item.rstrip() for item in f.readlines()]\n",
    "    with open(test_list, \"r\") as f:\n",
    "        test_names = [item.rstrip() for item in f.readlines()]\n",
    "\n",
    "    trg_base_dirs = [\n",
    "        os.path.join(target, \"train\"),\n",
    "        os.path.join(target, \"valid\"),\n",
    "        os.path.join(target, \"test\"),\n",
    "    ]\n",
    "    for item in trg_base_dirs:\n",
    "        if not os.path.isdir(item):\n",
    "            os.mkdir(item)\n",
    "\n",
    "    for root, _, files in os.walk(base):\n",
    "        for file_name in files:\n",
    "            if not file_name.endswith(\".wav\"):\n",
    "                continue\n",
    "\n",
    "            if \"_background_noise_\" in os.path.join(root, file_name):\n",
    "                continue\n",
    "\n",
    "            class_name = root.split(\"/\")[-1]\n",
    "            for item in trg_base_dirs:\n",
    "                if not os.path.isdir(os.path.join(item, class_name)):\n",
    "                    os.mkdir(os.path.join(item, class_name))\n",
    "            org_file_name = os.path.join(root, file_name)\n",
    "            trg_file_name = os.path.join(class_name, file_name)\n",
    "            if trg_file_name in valid_names:\n",
    "                target_dir = trg_base_dirs[1]\n",
    "            elif trg_file_name in test_names:\n",
    "                target_dir = trg_base_dirs[-1]\n",
    "            else:\n",
    "                target_dir = trg_base_dirs[0]\n",
    "            target_path = os.path.join(target_dir, trg_file_name)\n",
    "            shutil.copy(org_file_name, target_path)\n",
    "            print(f\"Copied {org_file_name} to {target_path}\")\n",
    "\n",
    "\n",
    "def SplitDataset(loc):\n",
    "    target_loc = \"%s_split\" % loc\n",
    "    if not os.path.isdir(target_loc):\n",
    "        os.mkdir(target_loc)\n",
    "    split_data(\n",
    "        loc,\n",
    "        target_loc,\n",
    "        os.path.join(loc, \"validation_list.txt\"),\n",
    "        os.path.join(loc, \"testing_list.txt\"),\n",
    "    )\n",
    "\n",
    "    sample_per_cls = sample_per_cls_v1 if \"v0.01\" in loc else sample_per_cls_v2\n",
    "    for idx, split_name in enumerate([\"train\", \"valid\", \"test\"]):\n",
    "        make_12class_dataset(\n",
    "            \"%s/%s\" % (target_loc, split_name), \"%s/%s_12class\" % (loc, split_name)\n",
    "        )\n",
    "        make_empty_audio(\"%s/%s_12class/_silence_\" % (loc, split_name), sample_per_cls[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b103446-89fe-4c10-a558-49145dcb9f5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bcreset/test_a.m4a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e6926a37b50a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mwav_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'bcreset/test_a.wav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm4a_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'm4a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\bcresnet\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fd_or_path_or_tempfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\bcresnet\\lib\\site-packages\\pydub\\utils.py\u001b[0m in \u001b[0;36m_fd_or_path_or_tempfile\u001b[1;34m(fd, mode, tempfile)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mclose_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bcreset/test_a.m4a'"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# M4A 파일을 WAV로 변환\n",
    "m4a_file = 'test_a.m4a'\n",
    "wav_file = 'test_a.wav'\n",
    "\n",
    "audio = AudioSegment.from_file(m4a_file, format='m4a')\n",
    "audio.export(wav_file, format='wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de1fabf-f1d8-43bc-9e6c-e1cce030e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# M4A 파일을 WAV로 변환\n",
    "m4a_file = 'test_b.m4a'\n",
    "wav_file = 'test_b.wav'\n",
    "\n",
    "audio = AudioSegment.from_file(m4a_file, format='m4a')\n",
    "audio.export(wav_file, format='wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0ee42-62db-46bb-a669-2953e15117f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcresnet",
   "language": "python",
   "name": "bcresnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
